{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "\n",
    "\n",
    "file_path = os.path.abspath(\".\")\n",
    "\n",
    "execution_path = os.path.abspath(f\"../../../../Binaries/Debug\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(file_path)\n",
    "import sys\n",
    "\n",
    "target_path = os.path.abspath(f\"../../../../Binaries/Debug\")\n",
    "sys.path.append(target_path)\n",
    "print(f\"Added {target_path} to sys.path\")\n",
    "package_path = os.path.abspath(f\"../python\")\n",
    "sys.path.append(package_path)\n",
    "print(f\"Added {package_path} to sys.path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glints.scratch_grid\n",
    "import glints.renderer\n",
    "import glints.test_utils as test_utils\n",
    "import torch\n",
    "import numpy as np\n",
    "import pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_to_gamma(image):\n",
    "    return image ** (1.0 / 2.2)\n",
    "\n",
    "\n",
    "def gamma_to_linear(image):\n",
    "    return image**2.2\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def save_images(field, resolution, divergence, smoothness):\n",
    "    for i in range(field.field.shape[2]):\n",
    "        test_utils.save_image(\n",
    "            1000 * divergence[:, :, i], resolution, f\"divergence_{i}.exr\"\n",
    "        )\n",
    "        test_utils.save_image(\n",
    "            100 * smoothness[:, :, i], resolution, f\"smoothness_{i}.exr\"\n",
    "        )\n",
    "\n",
    "        density = torch.norm(field.field[:, :, i], dim=2)\n",
    "        directions = field.field[:, :, i] / density.unsqueeze(2)\n",
    "        directions = torch.cat(\n",
    "            [directions, torch.zeros_like(directions[:, :, :1])], dim=2\n",
    "        )\n",
    "\n",
    "        test_utils.save_image(directions, resolution, f\"directions_{i}.exr\")\n",
    "        test_utils.save_image(density, resolution, f\"density_{i}.exr\")\n",
    "        test_utils.save_image(field.field[:, :, i, :1], resolution, f\"field_{i}.exr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "importlib.reload(glints.scratch_grid)\n",
    "os.chdir(execution_path)\n",
    "r = glints.renderer.Renderer()\n",
    "r.set_glints_roughness(0.0016 / 2)   # 划痕内部的粗糙程度，数值越大，划痕越模糊\n",
    "vertices, indices = glints.renderer.plane_board_scene_vertices_and_indices()\n",
    "camera_position_np = np.array([-2.0, 0.0, 6], dtype=np.float32) # 调参：相机位置，板子放在z=0平面上\n",
    "r.set_look_at(\n",
    "    camera_position_np,\n",
    "    np.array([0.0, 0.0, 0.0], dtype=np.float32),\n",
    "    np.array([-1.0, 0.0, 0.0], dtype=np.float32),\n",
    ")\n",
    "# r.set_camera_position(camera_position_np)\n",
    "fov_in_degrees = 35 # 调参：视场角\n",
    "resolution = [1200, 800] # 分辨率\n",
    "r.set_perspective(\n",
    "    np.pi * fov_in_degrees / 180.0, resolution[0] / resolution[1], 0.1, 1000.0\n",
    ")\n",
    "r.set_mesh(vertices, indices)\n",
    "# r.set_light_position(torch.tensor([-2.0, 0.0, 5.5], device=\"cuda\")) # 调参：光源位置\n",
    "r.set_light_position(torch.tensor([-2.0, 0.0, 2.5], device=\"cuda\")) # 调参：光源位置\n",
    "\n",
    "r.set_width(torch.tensor([0.001], device=\"cuda\"))\n",
    "\n",
    "field = glints.scratch_grid.ScratchField(400, 4) # 调参：划痕场，分辨率为400，第二个参数是子场的个数，每个子场会多占一份显存，散度和光滑度只在一个子场上计算\n",
    "image, sampled_mask = glints.scratch_grid.render_scratch_field(r, resolution, field)\n",
    "test_utils.save_image(image, resolution, \"scratch_field_initial.exr\")\n",
    "# target_image = r.prepare_target(\"texture.png\", resolution)\n",
    "\n",
    "loss_fn = (\n",
    "    lambda x, y: torch.nn.functional.l1_loss(x, y) * 1\n",
    "    + torch.nn.functional.mse_loss(x, y) * 1\n",
    ") # 调参，损失函数组合，作用在图像上\n",
    "regularization_loss_fn = torch.nn.HuberLoss() # 作用在散度、光滑度上，没啥可调的\n",
    "regularizer = torch.optim.Adam([field.field], lr=0.0001) # 目前没用\n",
    "optimizer = torch.optim.Adam([field.field], lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_count = 80 # 监督信号的数量\n",
    "angle_range = 20 # 监督信号的角度范围"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = []\n",
    "import cv2\n",
    "\n",
    "all_target_max = torch.tensor(0.0, device=\"cuda\")\n",
    "\n",
    "for i in range(target_count + 1):\n",
    "    target = cv2.imread(f\"targets/render_{i:03d}.exr\", cv2.IMREAD_UNCHANGED)[..., :3]\n",
    "    target = torch.tensor(target, dtype=torch.float32).cuda()\n",
    "    target = torch.rot90(target, k=3, dims=[0, 1])\n",
    "    targets.append(target)\n",
    "    all_target_max = torch.max(target.max(), all_target_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.makedirs(\"feifan/scratch_field\", exist_ok=True)\n",
    "# os.makedirs(\"feifan/target\", exist_ok=True)\n",
    "# for sub_field_id in range(field.field.shape[2]):\n",
    "#     os.makedirs(f\"feifan/directions_{sub_field_id}\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "\n",
    "\n",
    "for i in range(1000):\n",
    "\n",
    "    rnd_pick_target_ids = np.random.randint(0, target_count + 1, size=4)\n",
    "    init_id = np.random.randint(0, target_count + 1)\n",
    "    rnd_pick_target_ids = np.arange(init_id, init_id + 4, 2) % (target_count + 1) # 调参， batch size\n",
    "    # rnd_pick_target_ids = np.linspace(0, target_count, target_count + 1, dtype=np.int32)\n",
    "    iterative_rnd_pick_target_id = i % (target_count + 1)\n",
    "    # rnd_pick_target_ids[-1] = iterative_rnd_pick_target_id\n",
    "\n",
    "    camera_rotate_angle = (\n",
    "        iterative_rnd_pick_target_id * (angle_range / target_count) - angle_range / 2\n",
    "    ) * (np.pi / 180)\n",
    "    rotated_camera_position = test_utils.rotate_postion(\n",
    "        camera_position_np,\n",
    "        camera_rotate_angle,\n",
    "        axis=np.array([-1, 0, 0], dtype=np.float32),\n",
    "    )\n",
    "    r.set_look_at(\n",
    "        rotated_camera_position,\n",
    "        np.array([0.0, 0.0, 0.0], dtype=np.float32),\n",
    "        np.array([-1.0, 0.0, 0.0], dtype=np.float32),\n",
    "    )\n",
    "    image, sampled_mask = glints.scratch_grid.render_scratch_field(r, resolution, field)\n",
    "    test_utils.save_image(image, resolution, f\"feifan/scratch_field/scratch_field_{i:03}.exr\")\n",
    "    test_utils.save_image(\n",
    "        targets[iterative_rnd_pick_target_id], resolution, f\"feifan/target/target_{i:03}.exr\"\n",
    "    )\n",
    "\n",
    "    field.fix_direction()\n",
    "\n",
    "    for sub_field_id in range(field.field.shape[2]):\n",
    "        directions = torch.rot90(field.field[:, :, sub_field_id, :2])\n",
    "        test_utils.plot_arrows(\n",
    "            directions,\n",
    "            \"directions\",\n",
    "            spacing=6,\n",
    "            filename=f\"feifan/directions_{sub_field_id}/directions_{sub_field_id}_{i:03}.png\",\n",
    "        )\n",
    "        plt.close()\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    camera_positions = []\n",
    "    target_images = []\n",
    "\n",
    "    for rnd_pick_target_id in rnd_pick_target_ids:\n",
    "\n",
    "        camera_rotate_angle = (\n",
    "            rnd_pick_target_id * (angle_range / target_count) - angle_range / 2\n",
    "        ) * (np.pi / 180)\n",
    "        rotated_camera_position = test_utils.rotate_postion(\n",
    "            camera_position_np,\n",
    "            camera_rotate_angle,\n",
    "            axis=np.array([-1, 0, 0], dtype=np.float32),\n",
    "        )\n",
    "        camera_positions.append(rotated_camera_position)\n",
    "        target_images.append((targets[rnd_pick_target_id] / all_target_max) * 30)\n",
    "\n",
    "    print(f\"iteration {i}, target {rnd_pick_target_id}\")\n",
    "\n",
    "    losses += glints.scratch_grid.optimize_field(\n",
    "        field,\n",
    "        r,\n",
    "        resolution,\n",
    "        target_images,\n",
    "        loss_fn,\n",
    "        regularization_loss_fn,\n",
    "        regularizer,\n",
    "        optimizer,\n",
    "        epochs=1,\n",
    "        enable_smoothness_regularization=True, # 调参，是否启用光滑度正则化\n",
    "        enable_divergence_regularization=True, # 调参，是否启用散度正则化\n",
    "        camera_positions=camera_positions,\n",
    "    )\n",
    "\n",
    "\n",
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_rotate_angle = (10 * (20.0 / 20) - 10) * (np.pi / 180)\n",
    "rotated_camera_position = test_utils.rotate_postion(\n",
    "    camera_position_np,\n",
    "    camera_rotate_angle,\n",
    "    axis=np.array([-1, 0, 0], dtype=np.float32),\n",
    ")\n",
    "r.set_look_at(\n",
    "    rotated_camera_position,\n",
    "    np.array([0.0, 0.0, 0.0], dtype=np.float32),\n",
    "    np.array([-1.0, 0.0, 0.0], dtype=np.float32),\n",
    ")\n",
    "image, sampled_mask = glints.scratch_grid.render_scratch_field(r, resolution, field)\n",
    "test_utils.save_image(image, resolution, \"scratch_field.exr\")\n",
    "\n",
    "# test_utils.save_image(gamma_to_linear(target_image), resolution, \"target_image.exr\")\n",
    "divergence, smoothness = field.calc_divergence_smoothness()\n",
    "save_images(field, resolution, divergence, smoothness)\n",
    "\n",
    "image, sampled_mask = glints.scratch_grid.render_scratch_field(r, resolution, field)\n",
    "test_utils.save_image(image, resolution, \"scratch_field.exr\")\n",
    "\n",
    "directions = torch.rot90(field.field[:, :, 0, :2])\n",
    "\n",
    "\n",
    "test_utils.plot_arrows(directions, \"directions\", spacing=6, filename=\"directions.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# field.field.requires_grad = False\n",
    "# field.field = field.field.detach()\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# line_counts = []\n",
    "# for density_held in np.linspace(2.0, 3.0, 9):\n",
    "#     lines = field.discretize_to_lines(density_held, 0.4)\n",
    "#     line_counts.append(lines.shape[0])\n",
    "\n",
    "\n",
    "# plt.plot(np.linspace(2.0, 3.0, 9), line_counts)\n",
    "# plt.xlabel(\"Density held\")\n",
    "# plt.ylabel(\"Line count\")\n",
    "# plt.savefig(\"line_count.pdf\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = field.discretize_to_lines(\n",
    "    0.5, 0.5\n",
    ")  # 划痕离散化，卡住了调，第一个每根划痕带走的density，可以超过1，一般越大带走越快，每根越短，第二个参数是结束的阈值，不能超过1，越接近1结束越快\n",
    "print(lines.shape)\n",
    "lines = lines.cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(lines, \"lines.pt\")\n",
    "a = torch.load(\"lines.pt\")\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()\n",
    "r.set_type(\"bspline\")\n",
    "\n",
    "\n",
    "for i in range(target_count + 1):\n",
    "    camera_rotate_angle = (i * (angle_range / target_count) - angle_range / 2) * (\n",
    "        np.pi / 180\n",
    "    )\n",
    "    rotated_camera_position = test_utils.rotate_postion(\n",
    "        camera_position_np,\n",
    "        camera_rotate_angle,\n",
    "        axis=np.array([-1, 0, 0], dtype=np.float32),\n",
    "    )\n",
    "    r.set_look_at(\n",
    "        rotated_camera_position,\n",
    "        np.array([0.0, 0.0, 0.0], dtype=np.float32),\n",
    "        np.array([-1.0, 0.0, 0.0], dtype=np.float32),\n",
    "    )\n",
    "\n",
    "    image, _ = r.render(resolution, lines)\n",
    "    test_utils.save_image(image, resolution, f\"bspline_{i:03}.exr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir(execution_path)\n",
    "# import torch\n",
    "# lines = torch.load(\"lines.pt\")\n",
    "\n",
    "# r = glints.renderer.Renderer()\n",
    "\n",
    "# vertices, indices = glints.renderer.plane_board_scene_vertices_and_indices()\n",
    "# camera_position_np = np.array([4.0, 0.0, 3.5], dtype=np.float32)\n",
    "# r.set_camera_position(camera_position_np)\n",
    "# fov_in_degrees = 35\n",
    "# resolution = [768 * 2, 512 * 2]\n",
    "# r.set_perspective(\n",
    "#     np.pi * fov_in_degrees / 180.0, resolution[0] / resolution[1], 0.1, 1000.0\n",
    "# )\n",
    "# r.set_mesh(vertices, indices)\n",
    "# r.set_light_position(torch.tensor([0.0, 4.0, 4.5], device=\"cuda\"))\n",
    "\n",
    "# r.set_width(torch.tensor([0.001], device=\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
